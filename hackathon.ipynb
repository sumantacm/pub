{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN18OxQ0ENGZhBt1gTV8wCt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sumantacm/pub/blob/main/hackathon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "GdSKYnl0AwLN",
        "outputId": "f5cefa4e-e8b7-45fb-9bd1-c6c44524bfa6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'dementia_dataset.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f564359f22fc>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Reading the CSV file into a DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dementia_dataset.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Printing the shape of the DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dementia_dataset.csv'"
          ]
        }
      ],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
        "# Reading the CSV file into a DataFrame\n",
        "df1 = pd.read_csv('dementia_dataset.csv')\n",
        "\n",
        "# Printing the shape of the DataFrame\n",
        "\n",
        "print(df1.shape)\n",
        "\n",
        "df1.head(5)\n",
        "\n",
        "df1['Group'].unique()\n",
        "\n",
        "# # Filtering rows in df1 where the 'Group' column is equal to 'Converted' and assigning them to df2\n",
        "df2 = df1.loc[df1['Group'] == 'Converted']\n",
        "\n",
        "# # Dropping the rows from df1 that have been assigned to df2 using the corresponding index values\n",
        "df1 = df1.drop(df2.index)\n",
        "\n",
        "df2.head(10)\n",
        "\n",
        "\n",
        "# # Creating a new column 'Last_Visit' to identify the last visit for each patient\n",
        "df2['Last_Visit'] = df2.groupby('Subject ID')['Visit'].transform('max')\n",
        "\n",
        "# Updating the 'Group' column based on 'Visit' and 'Last_Visit' conditions\n",
        "df2.loc[df2['Visit'] < df2['Last_Visit'], 'Group'] = 'Nondemented'\n",
        "df2.loc[df2['Visit'] == df2['Last_Visit'], 'Group'] = 'Demented'\n",
        "\n",
        "# Dropping the 'Last_Visit' column\n",
        "df2.drop('Last_Visit', axis=1, inplace=True)\n",
        "\n",
        "# Displaying the updated DataFrame\n",
        "df2.head(5)\n",
        "\n",
        "# Combining the DataFrames df1 and df2\n",
        "frames = [df1, df2]\n",
        "df = pd.concat(frames)\n",
        "\n",
        "df['Group'].unique()\n",
        "\n",
        "# Renaming the 'M/F' column to 'Gender' in the DataFrame\n",
        "df.rename(columns={'M/F': 'Gender'}, inplace=True)\n",
        "\n",
        "# Display the current column names\n",
        "print(df.columns)\n",
        "\n",
        "# Drop unnecessary columns from the DataFrame if they exist\n",
        "columns_to_drop = ['Subject ID', 'MRI ID', 'Hand', 'Visit', 'MR Delay']\n",
        "existing_columns_to_drop = [col for col in columns_to_drop if col in df.columns]\n",
        "df.drop(columns=existing_columns_to_drop, inplace=True)\n",
        "\n",
        "df.isna().sum()\n",
        "\n",
        "# Imputing missing values in the 'SES' column with the mode\n",
        "df.SES.fillna(df.SES.mode()[0], inplace=True)\n",
        "\n",
        "# Imputing missing values in the 'MMSE' column with the mean\n",
        "df.MMSE.fillna(df.MMSE.mean(), inplace=True)\n",
        "\n",
        "df.isna().sum()\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Creating a count plot with 'Group' on the x-axis\n",
        "sns.countplot(data=df, x='Group', palette='Set2').set(title = 'Dementia Group');\n",
        "\n",
        "# Visualizing the distribution of 'Group' by 'Gender' using a count plot\n",
        "sns.countplot(data=df, x='Group', palette='Set2', hue='Gender').set(title = 'Dementia Group by Gender');\n",
        "\n",
        "# Visualizing the distribution of Education for each 'Gender' and 'Group'\n",
        "sns.displot(data=df, x='EDUC', col='Gender', palette='Set2', hue='Group', kind='kde');\n",
        "\n",
        "# Visualizing the distribution of 'Age' for each 'Group'\n",
        "sns.displot(data=df, x='Age', hue='Group', kind=\"kde\", palette='Set2');\n",
        "\n",
        "# Visualizing the correlation matrix of numeric columns using a heatmap\n",
        "sns.heatmap(df.corr(numeric_only=True), vmin=-1, cmap='coolwarm');\n",
        "\n",
        "# Check if 'ASF' column exists before dropping\n",
        "if 'ASF' in df.columns:\n",
        "    df.drop(columns=['ASF'], inplace=True)\n",
        "else:\n",
        "    print(\"Column 'ASF' not found in the DataFrame.\")\n",
        "\n",
        "# Visualizing the relationship between 'MMSE' and 'CDR' variables with respect to 'Group'\n",
        "sns.scatterplot(data=df, x='MMSE', y='CDR', palette='Set2', hue='Group');\n",
        "\n",
        "# Importing the necessary library for label encoding\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Creating an instance of the LabelEncoder class\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Encoding the 'Gender' column in the DataFrame\n",
        "df.Gender = le.fit_transform(df.Gender.values)\n",
        "\n",
        "# Printing the mapping of encoded values to original classes for 'Gender'\n",
        "print(f'Sex:\\n0 : {le.classes_[0]}\\n1 : {le.classes_[1]}\\n\\n')\n",
        "\n",
        "df.Group = le.fit_transform(df.Group.values)\n",
        "print(f'Group:\\n0 : {le.classes_[0]}\\n1 : {le.classes_[1]}')\n",
        "\n",
        "# Importing the necessary library for train-test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assigning the 'Group' column as the target variable\n",
        "y = df.Group\n",
        "\n",
        "# Assigning the remaining columns as the features\n",
        "X = df.drop(['Group'], axis=1)\n",
        "\n",
        "# Performing the train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Importing the necessary library for Random Forest classification\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Creating an instance of the RandomForestClassifier\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Fitting the model to the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the target variable for the test data\n",
        "y_hat = model.predict(X_test)\n",
        "\n",
        "\n",
        "# Importing the necessary libraries for performance evaluation\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "print('Accuracy Score:', accuracy_score(y_test, y_hat))\n",
        "print('Precision:', precision_score(y_test, y_hat, average='binary'))\n",
        "print('Recall:', recall_score(y_test, y_hat, average='binary'))\n",
        "print('F1 Score:', f1_score(y_test, y_hat, average='binary') )\n",
        "\n",
        "#prediction\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def predict_dementia(gender, age, educ, ses, mmse, cdr, etiv, nwbv):\n",
        "    # Encoding gender using LabelEncoder\n",
        "    gender_encoded = 0  # Default value for Male\n",
        "\n",
        "    if gender.lower() == 'f':\n",
        "        gender_encoded = 1  # Set to 1 for Female\n",
        "\n",
        "    # Creating a DataFrame with the input details\n",
        "    input_data = pd.DataFrame({\n",
        "        'Gender': [gender_encoded],\n",
        "        'Age': [age],\n",
        "        'EDUC': [educ],\n",
        "        'SES': [ses],\n",
        "        'MMSE': [mmse],\n",
        "        'CDR': [cdr],\n",
        "        'eTIV': [etiv],\n",
        "        'nWBV': [nwbv]\n",
        "    })\n",
        "\n",
        "    # Predicting dementia group using the trained model\n",
        "    probability_demented = model.predict_proba(input_data)[:, 1][0]\n",
        "    probability_percentage = probability_demented * 100\n",
        "\n",
        "    # Categorizing into Low, Mild, and High risk categories\n",
        "    if probability_demented < 0.33:\n",
        "        risk_category = \"Low\"\n",
        "    elif probability_demented < 0.66:\n",
        "        risk_category = \"Mild\"\n",
        "    else:\n",
        "        risk_category = \"High\"\n",
        "\n",
        "    # Formatting the probability as a percentage\n",
        "    probability_formatted = f\"{probability_percentage:.2f}%\"\n",
        "\n",
        "    return probability_formatted, risk_category\n",
        "\n",
        "# Example usage of the function\n",
        "gender = 'F'  # Replace with the actual gender (F or M)\n",
        "age = 70  # Replace with the actual age\n",
        "educ = 12  # Replace with the actual education level\n",
        "ses = 2.0  # Replace with the actual socioeconomic status\n",
        "mmse = 28.0  # Replace with the actual MMSE score\n",
        "cdr = 0.5  # Replace with the actual CDR score\n",
        "etiv = 1600  # Replace with the actual eTIV value\n",
        "nwbv = 0.7  # Replace with the actual nWBV value\n",
        "\n",
        "probability, risk_category = predict_dementia(gender, age, educ, ses, mmse, cdr, etiv, nwbv)\n",
        "print(f\"The probability of being demented is: {probability} ({risk_category} Risk)\")"
      ]
    }
  ]
}